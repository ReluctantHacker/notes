|#############################################################################################################|
1. some datastructure
	A. primitive: integer, float, string, boolean
	B. non-primitive: 
		a. 線性(in sequential order): list, tuple, array, linked list, stack, queue
		b. 非線性: set, dictionary, tree, graph

|#############################################################################################################|
2. Program Complexity
	A. Space complexity

	B. Time complexity
		a. f ∈ o(g)  ---   order(f)<order(g)  ---  lim f(x)/g(x) = 0 , x->∞
		a. f ∈ O(g)  ---   order(f)≤order(g)  ---  lim f(x)/g(x) < ∞ , x->∞
		a. f ∈ ϴ(g)  ---   order(f)=order(g)  ---  lim f(x)/g(x) ∈ R > 0 , x->∞
		a. f ∈ Ω(g)  ---   order(f)≥order(g)  ---  lim f(x)/g(x) > 0 , x->∞
		a. f ∈ ω(g)  ---   order(f)>order(g)  ---  lim f(x)/g(x) = ∞ , x->∞

|#############################################################################################################|
3. Recursive Algorithm(basic)
	A. Factorial
	B. Fibonacci Number
	C. Greatest Common Divisor(GCD)
	D. Binomial Coefficient
	E. Ackerman's Function
	F. Tower of Hanoi
	G. Permutation

	H. Recursive算法的大原則如下: 
	method_A: 由child到father進行運算, 也就是由所有leaf一路算回root (例子: binary tree的所有相關算法幾乎都是)
		def recursiveFunc():
			recursiveFunc()
			doSomething()

	method_B: 由father到child進行運算, 也就是由root一路算到所有leaf (例子: quickSort)
		def recursiveFunc():
			doSomething()
			recursiveFunc()

|#############################################################################################################|
4. array
	A. first dimensional array
	B. second dimensional array
		沒考過
	C. third dimensional array
		沒考過

|#############################################################################################################|
5. linked list
	A. 優點
		a. 動態性: 動態增加空間, 不需要一開始設定好
		b. 非連續性: 不需要連續的儲存空間
		c. 插入元素, 或刪除元素效率高: 時間複雜度O(1)

	B. 缺點:
		a. 隨機訪問效率低: 需要從頭查找, 時間複雜度O(n)
		b. 占用額外的空間
	
|#############################################################################################################|
6. stack
	A. ADT
		a. 性質:
			I. First in Last out(FILO)

		b. 操作:
			I. push(): push an element in stack's top position
			II. pop(): return the the top element and remove it from the stack
			III. peek(): return the top element
			IIII. isempty(): return if stack is empty or not
			IIIII. size(): return how many data in stack
			ps: 基本你會發現stack push, pop 都是對top作用, 所以增刪都在同一個位置
	B. array 實作
		a. 實作要點:
			I. 一個array, 長度依需求
			II. 一個int top, 紀錄top的位置
			III. top的初始化為-1, push則+1, pop則-1

	C. linked list實作:
		a. 實作要點:
			I. 一個data
			II. 一個*next, 指向下一個node
			III. 初始node為NULL
			IIII. 與array實作的方向相反, 在header的地方push(也pop), 
			IIIII. header node代表了這個stack
			IIIIII. NULL node 代表這個stack的結束位置

|#############################################################################################################|
7. 中序式與(後序式 or 前序式)互轉的演算法
	A. infix -> postfix
		a. 需要1個stack
		b. 由左向右scan
		c. 把"算符"push(pop)到stack(stack只會需要存算符)
	B. postfix的計算演算法
		a. 需要1個stack
		b. 由左向右scan
		b. 把"數字"push(pop)到stack(stack只會需要存數字)
	C. infix -> prefix
		a. 需要2個stack
		b. 由右向左scan
		c. 一個stack是temp, 一個是result
	D. prefix的計算演算法
		a. 需要1個stack
		a. 由右向左scan
		c. 把"數字"push(pop)到stack(stack只會需要存數字), 跟postfix很像, 只是計算時的次序要注意


|#############################################################################################################|
8. Queue
	A. ADT
		a. 性質:
			I. First in First out(FIFO)

		b. 操作:
			I. enqueue(): push an element in queue's rear position
			II. dequeue(): return the the front element and remove it from the queue
			III. isfull(): return if queue is full or not
			IIII. isempty(): return if queue is empty or not
			IIIII. front(): return the front element of the queue
			ps: 基本你會發現queue push, pop 分別在頭和尾, 所以增刪在不同位置
	B. array 實作
		a. 實作要點:
			I. 一個array, 長度依需求
			II. 一個int front, 紀錄front的位置
			III. 一個int rear, 紀錄rear的位置
			III. front, rear的初始化皆為-1, enqueue則rear++, dequeue則rear-1, front不變

	C. linked list實作:
		a. 實作要點:
			I. 一個data
			II. 一個*next, 指向下一個node
			III. 需要一個front node和一個rear node, 兩個打包成一個queue
			III. 初始front node 和 rear node 皆為NULL
			IIII. rear node enqueue, front node dequeue
			IIIII. NULL node 代表這個queue的結束位置


|#############################################################################################################|
9. Priority Queue
	A. ADT
		a. 性質:
			I. 不一定First in First out(FIFO)
			II. enqueue任意元素(權值)
			III. dequeue最大/最小 權值的元素

		b. 操作:
			I. 利用heap tree(簡稱heap), 
				🤔. 定義
					😄. 為一complete binary tree(故必定平衡)
					😄. 父node必定比子node大(max heap, 反之則為min heap), 
					😄. 所有子node皆符合上述定義
			ps: heap和heap sort大有關係!!!!


|#############################################################################################################|
10. Binary Tree(Tree 也屬於 graph)
	A. 總性質:
		a. 任意tree可化為binary tree
		b. 任意node最多只有兩個degree(分支)
		c. 左右子樹有次序之分(一般tree沒有特別定義)

	B. Full binary tree
		a. 性質:
			I. 必定平衡
			II. 除了leaf以外, 所有node當成root的子樹都必定為full binary tree
			III. 最後一個level填滿
			IIII. 公式:
				🤔. N = 2^H - 1   等價於  log_2(N+1) = H, N=node數, H為高度
				🤔. lN = 2^(H-1)

	C. Complete binary tree
		a. 性質:
			I. 必定平衡
			II. 除了leaf以外, 所有node當成root的子樹也都必定為complete binary tree
			III. 最後一個level未必填滿, 但是一定由左到右填入, 不會有跳過
			IIII. 公式: log_2(N+1) = H, 無條件退位

	D. Pathological Tree
		a. 性質:
			I. H = N, H=高度, N=node數
		b. left-skewed binary tree
		c. rigth-skewed binary tree

	E. 實作
		a. 使用array
			I. 優點:
				🤔. 對於full B.T完全沒有浪費空間
				🤔. 容易取得某node之左右子node, 以及父node的資料
					😄. 某node的編號為i則:
						😄. 左子node編號為2i, if 2i>N, 左子node不存在
						😄. 右子node編號為2i+1, if 2i+1>N, 右子node不存在
						😄. 父node編號為[i/2]([]:無條件捨位), if [i/2]<1, 則父node不存在
			II. 缺點:
				🤔. 節點增刪不易, 若空間不構, 要重新宣告array
				🤔. skewed B.T極度浪費空間

		b. 使用linked list(大部分實作還是用這個)
			I. 優點: 
				🤔. node增刪容易
				🤔. 對於skewed B.T
			II. 缺點: 
				🤔. 不易取得父node
					😄. 因為每個node只存左子node以及右子node
				🤔. link空間仍浪費約一半
					😄. 因為所有leaf的link皆沒有用到
			III. 實作:
				🤔. 每個node皆需要
					😄. data
					😄. left child node(c語言可用指標)
					😄. right child node(c語言可用指標)
				🤔. root代表了這棵樹
			
	 
|#############################################################################################################|
11. Binary Tree Traversal(操作上幾乎都使用recursive)
	A. breadth first(廣度優先) Traversal  -----> sibling 先走
		a. 由左到右
		b. 再由上到下
		c. 簡單來說就是同一level的先處理完再處理下一個level

	B. Depth first(深度優先) Traversal  ----> 子node先走, 這本身就包含recursive的概念, 因為把子node當作root進行重複操作, 
		a. 前序(preorder, DLR) Traversal, preorderTrav()
			I. 採用recursive
			II. time complexity: O(n)

		b. 中序(inorder, LDR) Traversal, inorderTrav()
			I. 採用recursive
			II. time complexity: O(n)

		c. 後序(postorder, LRD) Traversal, postorderTrav()
			I. 採用recursive
			II. time complexity: O(n)

		d. 給(inorder和preorder)排序結果, 回推binary tree
			I. preorder的root必定在最前面
			II. inorder的root必定在左右子tree的inorder中間
			III. 重複I, II

		c. 給(inorder和postorder)排序結果, 回推binary tree
			I. postorder的root必定在最後面
			II. inorder的root必定在左右子tree的inorder中間
			III. 重複I, II

		d. 給(preorder和postorder)排序結果, 回推binary tree
			I. 可能有很多種結果, 故無法

		e. 計算B.T node 總數, count()
			I. 採用recursive

		f. 計算B.T 高度, height()
			I. 採用recursive

		g. B.T每一node左右子tree交換, swap()
			I. 採用recursive

		
|#############################################################################################################|
12. Binary search tree
	A. 定義:
		a. 左子樹所有Node鍵値均小於Root鍵値
		b. 右子樹所有Node鍵値均大於Root鍵値
		c. 左、右子樹亦是Binary Search Tree

	B. 建立:
		a. 準備一段資料, 例如array
		b. 將array的首個資料當作root
		c. 接著按照binary search tree定義依序填入
		d. 平均時間複雜度: O(nlog n)
			I. 推導:
				🤔. total time complexity = log(1) + log(2) + log(3) + ... log(n) = log(n!)
				🤔. log(n!) = nlog(n) when n->∞, according to stirling formula(use intergral)
			若是不信, 以下還有一個討論:
			https://stackoverflow.com/questions/8118221/what-is-ologn-on-and-stirlings-approximation

		e. 最差時間複雜度: O(n^2)
			I. 剛我是一skewed tree
 
	C. 查找(search)
		a. 最壞情況O(n), 這棵樹剛好是skewed tree
		b. 平均情況O(log n)

	D. 插入(insert)
		a. 最壞情況O(n)
		b. 平均情況O(log n)

	E. 刪除(delete)
		a. 最壞情況O(n)
		b. 平均情況O(log n)

	F. 排序(sort), BST也可以用於排序(但資料必須先建立成BST)
		a. 用inorder traversal, 即可得到"由小到大"的排序結果
		b. 時間複雜度自然是traversal的複雜度O(n)
		c. 在tree sort實作中, 需要把"create tree"的複雜度也算進來, 所以總共還是要O(nlog(n))

	
|#############################################################################################################|
13. Tree 或 forest 化 Binary tree
	A. Tree 化 binary tree
		a. sibling之間建立link
		b. 每一個node只保留最左子node的link和剛才建立的sibling link, 其餘link皆斷

	B. Forest(many unlinked tree) 化 binary tree
		a. 所以tree皆化binary tree
		b. 將binary trees們的root建立link
		c. 以第一顆tree的root為新root


|#############################################################################################################|
14. 圖(Graph), 利用集合(set)的概念會很好理解
	A. 無向圖(undirected graph)
		a. G=(V, E), V=vertex, E=edge
		b. E通常表示(vi, vj), 其中vi, vj為兩相鄰vertex
		b. (vi, vj) != (vj, vi)

	B. 有向圖(directed graph)
		a. G=(V, E), V=vertex, E=edge
		b. E通常表示(vi, vj), 其中vi, vj為兩相鄰vertex
		c. (vi, vj) != (vj, vi)

	C. 完整圖(complete graph)
		a. 無向圖的完整圖
			I. 所有vertex都與其他vertex形成一個edge
			II. 若有n個vertex, 則共有n(n-1)/2個edge
		b. 有向圖的完整圖	
			I. 所有vertex都與其他vertex形成兩個(來回)有向邊edge
			II. 如有n個vertex, 則共有n(n-1)個edge

	D. 子圖(subgraph)	
		a. 集合V(G') 屬於 集合V(G) 且 集合E(G') 屬於 集合E(G), 則G'為G的subgraph

	E. 路徑(path)
		a. 定義:
			I. vertex v到v', 經過的所有edge的集合
		b. 長度(path length):
			I. edge的個數
		c. 簡單路徑(simple path):
			I. 除了頂點和終點, 其他點皆不同
				🤔. 若頂點和終點相同稱為"迴圈(cycle)"

	F. 連通(connected)
		a. for 無向圖
			I. 任意vertex與任意vertex之間皆有path存在, 即表示此圖connected

		b. for 有向圖
			I. 強連通(strongly connected)
				🤔. 任意vertex與任意vertex之間皆有path(雙向)存在
			II. 弱連通(weakly connected)
				🤔. 任意vertex與任意vertex之間皆有path(單項或雙向)存在
				🤔. 但是至少有一對vertex之間只有單向path(只能往, 不能返)
			III. 不相連(disjoint)
				🤔. 並非任意vertex之間皆有path(單向或雙向)
				🤔. 圖可以分成不相連的子圖
	
	G. 分支度(degree):
		a. for 無向圖
			I. 就是v有幾個e

		b. for 有向圖
			I. 入分支度(Indegree)
				🤔. 指向v的e個數
			II. 出分支度(Outdegree)
				🤔. 指出v的e個數
			III. 公式
				🤔. e = total_sum(indegree) = total_sum(outdegree)
				🤔. 從以上公式可以知道, 想要算總e, 只要算總indegree 或是 總 outdegree即可

	H. 資料結構(數學)如何表示graph?
		a. Adjacency Matrix(相鄰矩陣)
			I. for 無向圖(undirected graph)
				🤔. 此matrix為n*n, 縱向表n個nodes, 橫向也表n個nodes, 有link就1, 沒link就0
				🤔. 必為對稱矩陣
				🤔. (vi, vj)是否存在:
					😄. 檢查A[i][j]是否為1
						😄. 時間複雜度O(1)
			
				🤔. 求vi的e數:
					😄. 第i列 or 第i行 元素總和
						😄. 時間複雜度O(n) ---need 1 loop

				🤔. 求總e數:
					😄. total_sum(A[i][j])/2
						😄. 時間複雜度O(n^2)

			II. for 有向圖(directed graph)
				🤔. 矩陣的形式與無向圖一樣
				🤔. (vi, vj) <> (vj, vi), 故矩陣不一定對稱
				🤔. (vi, vj)是否存在:
					😄. 同無向圖
				
				🤔. 求vi的e數
					😄. Out-degree：求第 i 列之元素値總和。
						😄. 時間複雜度O(n) ---need 1 loop
					😄. In-degree：求第 i 行之元素値總和
						😄. 時間複雜度O(n) ---need 1 loop

				🤔. 求總e數:
					😄. total_sum(A[i][j]
						😄. 時間複雜度O(n^2)
		
		b. Adjacency List(相鄰串列)
			I. for 無向圖:
				🤔. 特性:
					😄. 跟linked list長的有點像, 但是意義完全不一樣, 不可搞混
					😄. 有n個node的graph, 用1維矩陣表示為A[i]
					😄. A[i] = vj|link -> vk|link -> vl|link........
					😄. A[i]存放的就是一個Adjacency List, 他表示與vi相連的vertex
					😄. Adjacency List的順序其實沒差啦 vj|link -> vk|link or vk|link -> vj|link都可
					😄. 此法所需node數(v|link)為2e (因為vi->vj, vj->vi都記錄下來了)
				
				🤔. (vi, vj)是否存在:
					😄. 檢查A[i]的adjacency list是否有node vj
						😄. 時間複雜度O(e/n) --- 這是平均和最差時間複雜度, 
							😄. 因為A[i]的adjacency list 長度正比於e
							😄. 平均而言len(A[i]) = e/n  (平均把所有node分散到每個A[i])
							😄. 你在長度e/n的串列做線性search, 自然複雜度O(e/n)
				🤔. 求vi的分支度(degree):
					😄. 求A[i]的adjacency list長度	
						😄. 時間複雜度O(e) ---
							😄. 因為要一個一個數, 所以跟複雜度search一樣

				🤔. 求graph的e數:
					😄. node總數/2
						😄. 時間複雜度O(n+e)
							😄. 找到A[i]需要O(1), traversal A[i]的adjacency list需要O(e), 所有處理一個A[i]總共要O(1+deg(vi))
							😄. 所有A[i]加總, O(1+deg(v1) + 1+deg(v2) + 1+deg(v3)... = O(|V| + |E|)
						😄. 當e為最大的時候e = n(n-1)/2, so 時間複雜度O(n+e) = O(n^2)
			
			II. for 有向圖(directed graph)
				🤔. 與無向圖幾乎一模一樣
	


|#############################################################################################################|
15. 圖(Graph)的traversal
	A. 需設定每一個node的visited flag
		a. flag=0: 尚未拜訪
		b. flag=1; 拜訪中
		c. flag=2; 已拜訪

	B. 深度優先(depth first traversal)----> 子node 先走
		a. 過程
			I. 選擇一個起始vertex vi, 
			II. 選擇一個與vi相連接且flag=0的vj, 並設定vj為新的起始點
			III. 以vj作為新的起始, 重複上述步驟
			IIII. 直到找不到下一個flag=0的vertex 

		b. 實作方法, 由於DFT有"recursive"的概念在其中(子node當作新root), 故可用stack來保存走訪中的vertex
			I. 選擇一個起始vertex vi, push到stack中
			II. 若stack不為空
				🤔. 從stack中pop()出top, 視為已拜訪
				🤔. top相接的所有flag=0的vertex都push進stack  ---> 重複執行
				🤔. 若所有vertex都被拜訪過, 而stack仍不為空, 則stack清空
			III. 若stack為空, 則traversal 結束
			IIII. DFT的順序不unique, 除非你自己設定按照某種排列


	C. 廣度優先(breadth first traversal) ----> sibling node 先走(遍歷所有silbling)
		a. 過程:
			I. 選擇一個起始vertex vi,
			II. 選擇一個與vi相連接且flag=0的vj, 
			III. 重複上述步驟(注意! 這個時候起始點還是vi, 沒有變)
			IIII. 接著對剛才走訪過的sibling重複上述步驟
			IIIII. 直到找不到下一個flag=0的vertex

		b. 實作方法, 使用"queue"來保存走訪中的vertex, 同樣是recursive
			I. 選擇一個起始vertex vi, enqueue到queue中
			II. 若queue不為空
				🤔. 從queue中dequeue()出front, 視為已拜訪
				🤔. front相接的所有flag=0的vertex都enqueue進queue---> 重複執行
			III. 若queue為空, 則traversal 結束
			IIII. BFT的順序不unique, 除非你自己設定按照某種排列



|#############################################################################################################|
16. AOV(Activity On Vertex)  ---> 其實就是一個有向圖的應用
	A. 定義:	
		a. 其實就只是一個有向圖(directed graph)
		b. vertex表示"工作(activity)"
		c. edge表示"工作的次數"(有方向嘛~)

	B. 拓撲順序(topological order, 或叫"拓撲排序") 
		a. 定義:
			I. 首先你的AOV圖不能有cycle
			II. 選一個起始vertex v_s和終點vertex v_e
			III. path v_s到v_e之間經歷的所有vertex, 不能有vi->vj但是vj的排序在vi之前

		b. 算法:
			I. 找出一個indegree=0的vertex
			II. 將此vertex輸出至result, 且刪除他的所有outdegree edges
			III. 重複I~II, 直到所有vertex接輸出至result, 或剩下的vertex都有indegree
			IIII. if 不是所有vertex都輸出至result, 則 沒有topological order
				🤔. 注意! AOV network圖若有cycle, 則必定沒有topological order(也就是無法決定那個工作先做)
				🤔. 注意! 不具cycle的AOV network圖, 則topological order >= 1組(不一定唯一)

	C. 資料結構如何表示?
		a. 使用adjacency list(不用adjacency matrix因為在這個case裡有點麻煩)
			I. 把A[i]改成一個2*n的矩陣A[c][i],  (就是多出一條來紀錄每個vertex的indegree數量)
				🤔. A[0][i] = count (vi的indegree數量)
				🤔. A[1][i] = vi的adjacency list

			II. 如何實作刪除vi的outdegree edge? (假設我們把vi丟到result, 同時也得刪掉她的outdegree edge才行)
				🤔. 假設A[1][i] = v1|link -> v2|link -> v3|link, 則
				🤔. A[0][1]--, A[0][2]--, A[0][3]--

				
				
|#############################################################################################################|
17. AOE(Activity On Edge, 就是常見的加權路徑圖)  ---> 也是就是一個有向圖的應用, 只是edge多了"加權值"
	A. 定義:	
		a. 其實就只是一個有向圖+edge權重
		b. vertex表示"事件(event)"
		c. edge表示"工作(activity"
			I. 有加權值, 通常表示所花費的time

	
	B. 應用:
		a. 求完成計畫藍圖所需的最少時間(最起碼)
			I. 求start_event->end_event之最長路徑(就是Critical path, 臨界路徑)
				🤔. 為何是求最常, 這裡有點反常識, 一下有個說明
					https://zhuanlan.zhihu.com/p/340950042

					😄. 其實就是所有的路徑其實要同時執行, 所以最長時間的路徑才是影響結果的關鍵
	
		b. 如何縮短完成計劃藍圖的時間?
			I. 找到所有critical path的交集工作(即egde), 並盡可能縮短他的權重
				

		
|#############################################################################################################|
18. 延伸二元樹(Extended binary tree)  ---> 用在霍夫曼樹(Huffman's tree)
	A. 定義
		a. 大部分的時候我們會使用linked list來表示B.T, 但是, 這樣leaf的link就沒有使用到, 挺浪費!

		b. Extended B.T會在leaf link連上一些特定的東西, 來幫助運算, 也順便空間在利用
			I. leaf link連上的node稱之為 "External Node" 或是 "Failure Node(因為如果搜索資料到了此處, 表示根本沒有要找的資料, 故return fail)"
			II. 其餘原本的node稱值為 "Internal Node"
			III. 根據B.T的性質, 很容易可以得到num(External_Node) = num(Internal_Node)+1

	B. 一些常用概念:
		a. 若I=sum_i(path_len(root->vi)), vi為internal node
		b. 若E=sum_i(path_len(root->vx)), vx為external node
		c. 則E=I+2n,  其中n為internal node總數
		d. 又若n固定, 則E與I成線性關係
		e. 越是balance的tree, E與I就愈小
		f. 但若是external node有加權值得時候, 上一概念 不一定成立!!!!(huffman's tree不一定要平衡!!)

	C. Weighted External Path length(W.E.P.L, 加權外部路徑長度), 其實就是每一個External path都要乘上各自的weight
		a. 定義:
			I. 即是 W.E.P.L = sum_x(path_len(root->vx)*weight_x)

		b. 性質:
			I. 沒有加權的情況下, 越平衡的樹, 搜索效率會越高, 總路徑長度(同時...平均路徑長度)會越短
			II. 但是有加權過後, 就不一定了

		
	D. 給定n個weight(也就是一定有n個external node), 如何求Min. W.E.P.L,  以及他對應的tree(就是huffman's tree了)
		a. Huffman's Algorithm: (與shannon theory裡面的entropy 大有關係, 但先不討論...)
			I. 設W為給定的weights的集合
			II. 算法如下:
				🤔. 將W中所有weight都設定為external node
				🤔. 自W中取出兩個最小的權重並相加(wi+wj), i
				🤔. 將(wi+wj)設定為wi和wj的父internal node
				🤔. 將(wi+wj)放入W中
				🤔. 重複上述步驟, 直到W中只剩一個weight(即是這顆huffman tree的root)

			III. Huffman Algo的精神:
				🤔. weight越大越應該離root近
				🤔. 從最小的weight開始建tree, 可以使大的weight更靠近root

			IIII. 經典應用:  編碼/解碼 的最佳情況
				🤔. 要傳遞一段英文訊息, 共有26個英文字母代號可用, 每個字母出現的頻率已知, 若要使用2進制(0, 1)來為26個字母編碼, 怎樣會節省空間, 最有效率?
					😄. 這個問題中, 字母頻率其實就是weight
					😄. Huffman tree root往左走代表0, 往右走代表1
					😄. 如此的編碼將會在平均上使傳遞的訊息 用最少的bit來表示, 最節省空間(因為他用了"min W.E.P.L", 同時編碼/解碼正比於bit數 所以 在平均上 也會達到最快(不可能更快了, 這跟信息entropy理論有關)
					😄. 其精神便是越常出現的字母, 其編碼使用的bit數要越少(即path長度越短)



|#############################################################################################################|
18. 自平衡二元搜索樹(self-balancing binary search tree)----> binary search tree的理論延伸 
	reference:
	https://zh.wikipedia.org/zh-tw/%E5%B9%B3%E8%A1%A1%E6%A0%91

	A. 目標:
		a. 我們知道binary search tree越是balance, 平均search效率就越高: log(n)--->事實上是最高了...
		b. 但我們在建構binary search tree的時候, 不見得會得到一顆平衡的樹, 我們需要些辦法獲得平衡的BST
		
	B. 常見的算法(方法), 大部分都使用了"旋轉(rotate)"的操作:
		a. AVL tree(AVL是人名縮寫) 
			I. 定義:
				🤔. 為一顆binary search tree, 且height 平衡(balance)
				🤔. 嚴格定義平衡(balance):
					I. |height(Lchild(root))-height(Rchild(root))| <= 1,  
						😄: height(Lchild(root)) 為 左子tree高度, 
                                                😄. height(Rchild(root)) 為 右子tree高度
				🤔. 左右子tree也是AVL tree

			II. 平衡因子(Balance factor, BF):
				🤔. BF = h_l-h_r
				🤔. 在AVL tree中, BF只可能是: -1, 0, +1

			III. 建構時出現的不平衡情況:
				🤔. LL不平衡: 
					😄. height(Lchild(root))-height(Rchild(root)) > 1, 
					😄. 且height(Lchild(Lchild(root))) > height(Lchild(Rchild(root)))
					😄. 翻譯成人話: height(左子tree) - height(右子tree) > 1
					😄. 且height(左子tree的左子tree) > height(左子tree的右子tree)
				🤔. LR不平衡
					😄. height(Lchild(root))-height(Rchild(root)) > 1, 
					😄. 且height(Lchild(Lchild(root))) < height(Lchild(Rchild(root)))
					😄. 翻譯成人話: height(左子tree) - height(右子tree) > 1
					😄. 且height(左子tree的左子tree) < height(左子tree的右子tree)
				🤔. RL不平衡
					😄. height(Lchild(root))-height(Rchild(root)) < -1, 
					😄. 且height(Rchild(Lchild(root))) > height(Rchild(Rchild(root)))
					😄. 翻譯成人話: height(左子tree) - height(右子tree) < -1
					😄. 且height(右子tree的左子tree) > height(左子tree的右子tree)
				🤔. RR不平衡
					😄. height(Lchild(root))-height(Rchild(root)) < -1, 
					😄. 且height(Rchild(Lchild(root))) < height(Rchild(Rchild(root)))
					😄. 翻譯成人話: height(左子tree) - height(右子tree) < -1
					😄. 且height(右子tree的左子tree) < height(左子tree的右子tree)

			IIII. 調整不平衡的算法, 採用旋轉的方法:
				🤔. 其實你根本不用管是哪種不平衡, 只要記住以下
					😄. 最大的值擺在R_child, 最小的值擺在L_child, 中間值擺在root
					😄. 若發生不平衡的插入值不再以上3個值之內, 則此插入值重插

			IIIII. 高度-節點數定理
				🤔. 建立高度h的AVL tree, 最少需要多少解點?
					😄. 答: Fibonacci(h+2) - 1,   Fibonacci(n)為費氏數列第n項

				🤔. 範例1:
					😄. 高度3的AVL tree, 至少要Fibonacci(3+2)-1 = Fibonacci(5)-1 = 4個節點
					😄. 高度3的AVL tree, 最多要?
						😄. 就是盡量建立成full tree, 所以答案是 2^h - 1 = 7

				🤔. 範例2:
					😄. 一個AVL tree有15個nodes, 則他的最大高度為?
						😄. Fibonacci(h+2)-1 <= 15 < Fibonacci(h+2+1)-1
							😄. 答: h = 5
					😄. 一個AVL tree有15個nodes, 則他的最小高度為?
						😄. 就是儘量建立成full tree, 答案: log(n+1)=4 (無條件退位, 跟complete tree的高度算法是一樣的)
		
		b. 樹堆(Treap)

		c. 伸展樹(Splay tree)
	
		d. 紅黑樹(Red-black tree)

		e. 加權平衡樹(weighted balanced tree)


						
|#############################################################################################################|
19. m-way search tree (binary search tree的擴展)   *****---- degree>2的樹, 高考好像沒考過*****
	A. 定義:
		a. 每個node可以有多個key, 但key的數量不超過(m-1)個, 但也至少要有1個key
		b. 每個key各有兩個degree(左右)
		c. 根據以上, 可以得到一個結論: 每個node的degree有m個, 且至少2個(你至少有1個key)
		d. node的key由小排列到大
		e. 各node的子tree同樣是m-way search tree
		f. 子tree內的所有資料皆小於他的父key
		
	B. 目的:
		a. 資料量龐大的時候, binary search tree高度太大(搜索慢), 如果node的degree多一點, 可以有效降低高度
			I. 外部搜索(External Search)
				🤔. 把資料放在記憶體以外的儲存空間進行處理
			II. 內部搜索(Internal Search)
				🤔. 把資料放在記憶體處理, 但是空間很有限, 資料量不能太多


|#############################################################################################################|
20. B-tree           *****---- degree>2的樹, 高考好像沒考過*****
	A. 定義:
		a. 即是一個balanced的m-way search tree! 
		b. 除了root及failure node之外, 其餘node的degree介於[m/2]至m  ----> 重點!!!
		c. 所有failure node在同一個level, 所有leaf在同一個level

	B. 最簡單的B-tree:    2-3 tree:
		a. 就是m=3(你如果m=2就變成balanced B.S.T), 根據定義任意node的degree介於2到3

	C. 操作
		a. Insert:
			I. 過程可能會遇到node裡面key數量超過m-1的狀況(overflow), 需要"split"
				🤔. split的辦法:
					😄. 將第[m/2]key 拉到父node, 其餘keys拆分成左右2個node
					😄. 這個辦法能保證你的B-tree一直是B-tree

		b. delete:
			I. 先找到要delete的鍵值, 假設為x
			II. 過程可能遇到node裡面key數量低於[m/2]-1(underflow), 這個時候需要"rotate"或"combination", 以下分為2種狀況:
				🤔. x在leaf:
					😄. 檢查拿掉x後有無underflow
						😄. 若無則OK
						😄. 如有
							😄. 嘗試rotation
							😄. rotation 不可行, 則做combination
							😄. 接著檢查combination完後, 父node有無underflow
							😄. rotation, combination的發法請參考講義(有點複雜)
							😄. rotation, combination的大原則如下:
								😄. rotation: 若x node underflow, 則其sibling送key給父node, 父node在送key給x node
								😄. combination: 若x node underflow, 且其sibling沒有key可送, 則父node送key給x node, 並把x node與其他sibling合併

				🤔. x在非leaf node:
					😄.  以x的右子樹中之最小鍵値取代x；或
					😄.  以x的左子樹中之最大鍵値取代x

	D. 應用
		a. 資料庫索引(index)
			I. 其採用的辦法正是B-Tree資料結構, 
				原理: 為何可以增加搜索數據的速度, 其實不難理解, 資料存入資料庫若是沒有任何資料結構, 那搜索將採用線性搜索, 也就是時間複雜度是O(n), 如果做了B-Tree的索引結構, 那搜索速率自然提升到O(log(n)) 補充: 雖然索引(index)會使搜索效率提升, 但是insert, 或update的速率是會下降的, 因為他需要先找到, 才能插入或update, 但是沒做索引的話, 直接插入就好, 不用理會index的結構到底如何
			
