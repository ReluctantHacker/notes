|###################################################################|
A. 牛頓力學的理論基礎:
        -------------------------------------------------------------
	a. 簡史:
		I. 在前牛頓時代沒有定義"力", 由於力的定義是物體是否獲得加速度, 所以定義了"力", 同時也定義了"慣性(有力則變速, 無力則勻速)", "力"和"慣性(慣性質量)"實際上綁在一起講的, 在講同一件事情.
		II. 天文學沒有牛頓力學的支持就是玄學了.

        -------------------------------------------------------------
	b. 牛頓三大運動定律(Newton's three laws of motion):
		I. 慣性定律(Law of Inertia)
		II. 定義F=ma 或 F=dP/dt
		III. 作用力=反作用力
		IV. 以上3個定律實際上都是在講F=ma(dP/dt), 在封閉的系統中(沒有外力), 三條定律是同一個定律. 例如把兩個粒子當成一個系統, 由於這個系統沒有外力, 所以A粒子吸引B粒子, 那B粒子必定用相同的模式吸引A粒子. 這其實也就是"動量守恆(有外力則動量變, 無外力則動量不便)", 
			🤔. 動量守恆或者所謂作用力等於反作用力, 本質其實是微觀粒子的"同質性"以及"空間對稱性(及粒子擁有的物理定律不隨位置改變)"的展現, 以下是文字說明:
				😄. 其實是這樣的, 當有兩個粒子完全相等時, 他們會具有一樣的性質, 例如你玩street fighter, 你和對手都玩春麗, 那兩方的招式會一膜一樣, 如果這個時候行為模式也一樣, 那就是兩個相同粒子了! 兩個粒子因為一樣, 如果A粒子吸引B粒子, 那B粒子也會以完全一樣的形式吸引A粒子(注意! 這裡沒有主次! 兩方都是主動的! 因為兩個人行為完全一樣! "作用力與反作用力"這名詞容易讓人誤會, 以為A粒子是主動的, B粒子被動給予回饋, 但是! 不是的! 兩個人都是主動的! 你推牆壁, 你以為牆壁反推你, 其實也可以說是牆壁主動推你, 你反推牆壁. 兩個粒子的相互作用並沒有因果關係. 如果微觀粒子情況下作用力=反作用力, 那巨觀必定也是成立! 故而所以!

        -------------------------------------------------------------
	c. 牛頓萬有引力定律(Newton's law of universal gravitation):
		I. 牛頓的天才之處在於他想到了日月星辰的運動與蘋果掉落是被同一種作用力支配的.
		II. 定律的描述如下:
			🤔. F與雙方距離平方成反比
			🤔. F與雙方質量成正比
			🤔. 以上兩個統合即是: F=GMm/(r^2)
		III. 定律的本質:
			🤔. 設想是這樣的, 兩個物體若要互相吸引, 則他們之間的力要與兩物體的某種"性質"相關, 這個性質稱為"重力質量(這個新假想的性質並不等於慣性質量, 是不同東西, 但為了方便我們稱它為質量, 之後百年後會證明兩者就是同一種東西, 因為重力等價於慣性力, 這是愛因斯坦廣義相對論的等效原理, 但我們這裡都先當成兩種質量是不同東西)", 事實上在牛頓的年代也已經觀察到, 他們使用法馬之類磅秤測量重力時, 重力質量等比例於慣性質量, 但是牛頓沒有深入去細究兩者的本質.
			🤔. 另外要與距離平方呈反比, 這個從科普勒的行星定律可以推知一二. 其實最早有此概念的人還有虎克(也是個牛人), 雷恩, 哈雷等人, 很多科學家們互相交流, 互相研究才慢慢萌芽的, 17世紀中已經有不少人知道太陽有吸引力, 並且認為支持日心說.

|###################################################################|
B. 重要數學概念:
        -------------------------------------------------------------
	a. 微積分(底層概念)
		I. 微分:
			🤔. f(x)微分即df(x)/dx=[f(x+dx)-f(x)]/dx, 其中d為取無窮小 
			🤔. 大部分的f(x)可以展開成多項式(多項式即各項指數為自然數, 自然數即非負整數, 例如x^0+x^1+x^2...就是多項式), 當年牛頓已經猜到了只要知道x^N(其中N為任意在然數)的微分規則, 則大部分的函數微分都能利用多項式展開得到分析方式
			🤔. 任意函數f(x)=x^N, 其中N為自然數, 則f(x+dx)=(x+dx)^N, 我們可以把(x+dx)^N看成(a+b)^N, (a+b)^N的展開所需的數學理論叫做"二項式定理", 即(a+b)^N=Sigma_C(N, n)a^n*b^(N-n), 其中n從0到N.
				😄. 二項式定理的證明(此定理可推出多項式微分定理)
				reference:
				https://www.naer.edu.tw/upload/1/16/doc/864/%E6%99%AE%E9%AB%98%E6%8E%92%E5%88%97%E7%94%9F.pdf
					😄. 需要先理解排列(permutation), 組合(combination), 基礎概念可以參考數學筆記中的"離散數學", "機率"
					😄. 排列(permutation):
						😄. 重複排列:
							😄. m種不同物件, 任意選取n個排成一列, 每種物件可無限制重複, 共有m^n種排列(排序)方式, 記做P'(m, n)
						😄. 非重複排列:
							😄. m種不同物件, 任意選取n個排成一列, 每種物件"不"可重複, 共有m*(m-1)*(m-2)*...(m-n+1)=m!/(m-n)!種排列(排序)方式, 記做P(m, n), 若n=m或n=m-1則即是有m!種排列.
					😄. 組合(combination):
						😄. 重複組合:
						reference:
						https://cosmicmathschool.blogspot.com/2022/04/h.html?m=1
						https://www.mathsisfun.com/combinatorics/combinations-permutations.html
							😄. m種不同物件, 任意選取n個組合成一堆(不考慮此n個元素的堆中的排序, 即是ABC同BCA同CAB等等), 每種物件可無限制重複, 共有(m+n-1)!/[n!*(m-1)!]種組合, 記做H(m, n). 詳細說明請繼續閱讀.
							😄. 一次(未知數均為一次方)不定方程(indeterminate equation, 又稱丟翻圖方程, 即不只一個解的方程, 例如x1+x2=a, a為某個常數)的非負整數(自然數)解數量即是一種重複組合問題. 例如: 小王去飲料店購買5杯飲料, 該店售賣3種飲料(假設為A, B, C三種), 所以小王共有H(3, 5)種購買方式, 也可以將此問題寫成不定方程x1+x2+x3=5, 其中x1表示A種飲料的購買數量, x2表示B種飲料購買數量, x3表示C種飲料購買數量. 寫成(x1, x2, x3). 例如若為(1, 2, 2), 則圖像標記為o|oo|oo,o表示飲料, '|'表示分類隔板, 最左邊是A飲料, 中間表示B飲料, 最右邊表示C飲料. 我們可以發現這個問題實際上等於5個o和2個|進行重複排列, 所以很直觀的可以知道他的數量就是(5+3-1)!/[5!*(3-1)!]=P(5+3-1, 5+3-1)/[5!*(3-1)!]
						😄. 非重複組合:
							😄. m種不同物件, 任意選取n個組合成一堆(不考慮此n個元素的堆中的排序, 即是ABC同BCA同CAB等等), 每種物件不可重複, 共有m!/[n!*(m-n)!]種組合, 記做C(m, n). 其實就是P(m, n)/n!, 因為他等於是把P(m, n)中n的排序次數n!除掉了. 所以P(m, n)可推倒出C(m, n)
					😄. 二項式定理證明:
						😄. 每一項實際上都是一個組合問題, 舉一個最簡單的例子(a+b)^2=(a+b)*(a+b)=(a1+b1)*(a2+b2), 這裡a1和a2都是a, 為了方便說明才加以區分. 可以看到(a1+b1)*(a2+b2)=a1*a2+b1*a2+a1*b1+b1*b2, 會發現只有a1*a2而沒有a2*a1(你也可反過來乘, 如此只會有a2*a1而沒有a1*a2), 只有b1*b2而沒有b2*b1, 只有a1*b1而沒有b1*a1, 只有b1*b2而沒有b2*b1, 所以a1*a2等等項的乘法"排列順序"不需考慮, 只需算一次. 而稍微思考一下, 就能想到此情況在(a+b)^n其中n>=2的情況的各項都是適用的, 所以我們可以得知(a+b)^n的各項a^x*b^(n-x)可以寫成n!/[x!*(n-x)!], 即是C(n, x)
					😄. 牛頓廣義二項是定理, 即是尋找(a+b)^c展開式, 其中c為實數, 牛頓當年就在研究(1-x^2)^(1/2)的無窮展開多項式(即是"無窮級數", 無限項的多項式). 
						😄. 牛頓將二項式定理的次方推廣到實數, 以下是一些有趣的經過(牛頓的年代已經知道無窮級數展開了)
						reference:
						https://ccjou.wordpress.com/2013/11/01/%E7%89%9B%E9%A0%93%E7%9A%84%E4%BA%8C%E9%A0%85%E5%BC%8F%E5%AE%9A%E7%90%86-%E4%B8%8A/
						https://ccjou.wordpress.com/2013/11/05/%e7%89%9b%e9%a0%93%e7%9a%84%e4%ba%8c%e9%a0%85%e5%bc%8f%e5%ae%9a%e7%90%86-%e4%b8%8b/
						https://www.zhihu.com/question/56009060
		II. 無窮級數(infinite series, 研究微積分時必然伴隨著大量無窮級數的研究)
			🤔. 牛頓可以說是第一個利用無窮級數解決數學問題的人, 將其用在他的微積分研究

        -------------------------------------------------------------
	b. 座標變換(coordinate transformation), 線性代數:
		I. 基礎概念:
			🤔. 定義"向量空間", 其實"空間(space)"就是有結構的"集合(set)", 向量空間的集合元素是"向量(抽象的向量)", 這些向量有線性代數的疊加特質
			🤔. 座標變換有線性和非線性, 但本質一樣, 都是將試圖將一個向量在一個座標系底下表示, 例如向量V在A座標系統之下(也可理解為基底)為[1, 1], 在B座標系統之下為[2, 3]. 
			🤔. 而座標變換就是A的"全部"向量, 在B之下如何表示. 可以透過"轉換矩陣(transformation matrix)", 來把A之下的任意X向量輸入進矩陣M中, 輸出一個在B之下的向量表示結果X'. 
			🤔. 其實整體概念就是把"函數"的映射概念拓展到向量去了, 所謂的矩陣就是"函數", 而向量就是"數值". 
			🤔. 也可以理解為"基底變換", 例如在A座標系統下的基底, 變化為B座標系統下的基底, 則A系統向量V經過基底變換後, 對應的向量是甚麼(這個基底變換所造成的向量變換就是M矩陣在做的事情).  
			🤔. 有一點必須注意的是! A基底的原始狀態我們並不知道(B也不知), 我們只知"A, B的變換關係"! 例如A系統下向量[1, 1], 這只表示兩個基底各有一個數值, 但無法從中得知基底結構(當然如果你假設有個C系統他是絕對平坦(直角坐標), 用C來架構A, B, 那便能知道, 但是A, B之間的關鍵關係仍然是變換矩陣M), 對A來說自己便是平坦的二維空間, 對B來說也會認為自己是平坦的二維空間, 兩者只有相對變換關係(M矩陣)
			🤔. 我們可以得到一個結論, 就是變換矩陣, 在幾何上其實就是兩個不同基底的座標系統的"變換橋梁"
			🤔. V經過M得到V', 而V'經過逆矩陣M^(-1)得到V
			🤔. 設A為絕對平坦座標系, 其基底為e1=(1, 0), e2=(0, 1). 可經過M變換到B座標系. 在B座標系自己看來, 自己的基底也是同樣型式f1=(1, 0), f2=(0, 1), 若是想要求得B的基底在A之下如何表達(也就是說B的基底在A看來是甚麼樣子), 可以直接用逆矩陣M^(-1)對f1和f2做輸入運算求得, 即是, M^(-1)f1=(x1, y1), 也即是f1在A看來是(x1, y1)
		II. 線性變換(座標變換最常見也最簡單的形式)
			🤔. 若(aV+bX)M = aVM+bXM, 其中V和X為任意向量, a, b為任意常數, 則M矩陣為線性.
			🤔. 旋轉, 縮放(拉伸), 反射都是線性變換的一種, 線性矩陣的本值就是線性變換(就是拉伸, 旋轉, 反射)
			🤔. eigenvalue, eigenvector
				😄. 一般情況下, 直觀理解, 你可想像一個像皮膜, 其"拉伸"的方向(可能不只一個)就是特徵向量(eigenvector), 而拉伸的程度(大小)就是特徵值. 由於特徵方向本身是拉伸的方向, 那很自然他在經過拉伸變換後方向保持不變.(如果你只拉伸一個方向, 與該方向垂直的方向會自動成為特徵向量, 這是因為與之垂直的那個方向因為線性獨立的性質, 所以不會受到拉伸的任何影響, 也就是說拉伸前後不便, 即是特徵向量了), 非特徵向量均會向特徵向量"靠攏(轉動)". 需要注意的是eigenvalue和eigenvector等等概念只有在"方陣"才適用, 若矩陣A不是方陣, 則A沒有eigenvalue和eigenvector, 此時A仍舊有singular value和singular vector
				😄. 旋轉情況下, 由於特徵向量和特徵值都是複數, "拉伸"的概念需要做一個延伸
					😄. 複數概念, 所有複數均可以表示為Z=A*e^(i*theta)=A*[cos(theta)+i*sin(theta)], 其中A為實數常數, 可畫到複數平面上(縱軸為虛數, 橫軸為實數, 與實數的夾角為theta), 且有性質Z1*Z2=A1*e^(i*theta1)*A2*e^(i*theta2)=A1*A2*e^(i*(theta1+theta2)), 其實就是Z1被Z2拉伸(或擠壓)且旋轉
					😄. 複數概念2, 複數的"長短", 我們必須自己定義(就好像實數的大小依靠排序order, 雖然實數較為直觀, 但其實那也是我們自己定義出來的), 通常定義複數長度為"一個複數在複數平面上距離原點多遠", 即若Z=a+bi, 則|Z|^2=a^2+b^2=Z*Z', 其中Z'為Z的共軛複數(即是虛部取反數). 
					reference:
					https://math.stackexchange.com/questions/1116022/can-a-complex-number-ever-be-considered-bigger-or-smaller-than-a-real-number
					😄. 複數概念3, 若Z1*Z2=(x+iy)*[cos(theta)+i*sin(theta)]=[x*cos(theta)-y*sin(theta)]+i*[y*cos(theta)+x*sin(theta)]=矩陣向量相乘[[cos(theta), -sin(theta)], [cos(theta, sin(theta)]]*[x, y], 也即是Z2讓Z1旋轉了theta角度, 而[[cos(theta), -sin(theta)], [sin(theta, cos(theta)]]就是旋轉矩陣, [x, y]就是輸入向量. 所以複數平面的概念直接與旋轉矩陣的概念連在一起了.
					😄. (補充)這個時候就再提到"複數平面"的概念了. 我們在解一些二元方程時, 例如y-1=x^2, 我們會得到複數(它是實數的擴充)解s1=(i, 0), s2=(-i, 0), 這個時候若是只在x-y平面上, 是無法把s1, s2畫出來的, 但是! 若我們多設一個z軸, 把原本的x軸當作x的複數解的實部, z軸當作x的複數解的虛部. 那這個幾何意義就出來了!! x-z平面其實就是x的複數平面, 他的旋轉性質大家都知道, 原本若只考慮實數解, 則解一直都在x-y平面上, 但是若是x有了複數解, 則該解已經不在x-y平面上了, 解與z軸的角度不再是90度(你可以試著畫出來就知道了).       
					😄. 旋轉矩陣R(theta)=[[cos(theta), -sin(theta)], [sin(theta), cos(theta)]]=[[a, -sqrt(1-a^2)], [sqrt(1-a^2), a]], 其中a=cos(theta). 可以算得特徵值λ1=a+sqrt(a^2-1)=cos(theta)+i*sin(theta)=e^(i*theta), 對應的特徵向量V1=[sqrt(a^2-1), sqrt(1-a^2)]=[i*sin(theta), sin(theta)]. 特徵值λ2=a-sqrt(a^2-1)=cos(theta)-i*sin(theta)=e^(-i*theta), 對應的特徵向量V2=[sqrt(1-a^2), sqrt(a^2-1)]=[sin(theta), i*sin(theta)]. 
					😄. 任何輸入向量可用特徵向量展開V=[x, y]=C1*V1+C2*V2=C1*[sqrt(a^2-1), sqrt(1-a^2)]+C2*[sqrt(1-a^2), sqrt(a^2-1)], 將向量輸入矩陣M*V=C1*λ1*V1+C2*λ2*V2. λ1*V1是複數乘上一個複數的向量, 但是記住這個向量被乘後並無發生轉動!!! 是該向量的分量在其複數平面發生了轉動, "一個向量只要分量的比值固定, 即是方向不變", 所以λ1*V1, 並不會讓V1方向發生改變, 即使λ1是複數(只是讓分量的複數平面轉動, 別搞錯), 只是讓V1的"長度"發生了改變.
					😄. 定義有複數的向量的大小, 我們之前定義過"向量空間", 現在在向量空間的架構上定義"內積", 即是""內積空間", 有了"內積"即能定義"向量"的大小和角度(這個不是只有複數共用, 實數也是全部通用). 我們讓向量v(dot)w=v1*w1'+v2*w2'+....., 其中w1'表示w1的共軛複數. 以此方式定義"內積"不但能兼容純實數時的內積定義, 還能讓複數情況的"複數"長度有意義.
					😄. 複數向量的內積可以用來計算向量的"角度"和"長度", 通常兩向量正交或平行時內積為純實數, 但其他狀況的內積結果都為複數, 複數的內積無法直接表示為"長度"和"角度", 但是它有深刻意義.(關於複數的更進一步的內容一定要參考"複變分析", "複變函數", 其實就是一個函數的輸入是複數, 輸出也是複數)
			🤔. 矩陣的深層涵義
				😄. 矩陣本身是"線性變換"的引擎, 但是他其實有一個深意, 舉個簡單的例子就能明白. 例如矩陣A=[[x1, x2], [y1, y2]], 表準基e1=[1, 0], e2=[0, 1]. 計算A*e1=[x1, y1], A*e2=[x2, y2], 所以實際上矩陣A(線性變換)的每一列就是標準基從原本座標系統映射到輸出座標系統的結果!, 每一列可以看做是標準基的映射向量(逆矩陣的每一列自然就是輸出座標系統基底映射回原始座標基底的結果).
			🤔. 向量子空間(線性子空間)
			reference:
			https://www.youtube.com/watch?v=pMFv6liWK4M&ab_channel=KhanAcademy
			https://math.stackexchange.com/questions/1961727/the-need-for-the-gram-schmidt-process
				😄. 若Rn表示n維歐幾里得向量空間(Rn有封閉性), 則由Rn的一些向量線性組合所構成新的空間Sm若能符合以下2個條件則Sm為Rn的向量子空間:
					😄. 在Sm本身中進行向量運算, 其結果仍是在Sm內(保有封閉性)
					😄. Sm至少包含0向量(非空性)
				😄. span(v1, v2, v3)表示由v1, v2, v3所生成的向量空間. 通常表示為span(v1, v2, v3)=a1*v1+a2*v2+a3*v3, 其中a1, a2, a3是任意標量(實數或複數)
				😄. 有時候為了探討一些子空間的問題, 我們不能!也不會!使用Rn以及[1, 0], [0, 1]這種基底(他是Rn的基底, 但是若作為Rn子空間Sm的基底很可能無法滿足封閉性, 會組合出Sm以外的向量, 所以不能用), 假設若Sm為Rn的子空間且Sm=span(v1, v2, ...vm), 即是vi組成了一個Rn的線性子空間, vi之間線性獨立但未必正交, 若要以v1為基點正交化基底, 則Gram-Schmidt方法即是專門設計用來找到"該子空間"的正交基底(妳若是使用[1, 0], [0, 1]則span出來就不一定是在該子空間了, 不一定滿足子空間封閉性! 所以不能使用[1, 0]...這是關鍵概念), Gram-Schmidt法的精髓如下:
					😄. 子空間的一組基底(非正交)為v1, v2, v3.....
					😄. 選取v1作為一個正交基底
					😄. 把v2有關v1方向的分量去除(利用投影法), 得到一個u1與v1正交, 此u1則是第二個正交基底
					😄. 把v3有關v1和u1方向的分量都去除(同樣利用投影法), 得到一個u2與u1和v1都正交, 此u2則是第三個正交向量
					😄. 如此類推求出所有的正交向量, 最後正規化(規一).
				😄. (此範例[1, 0]可適用)假設一個物體在平面R2上運動, 他每次只能走v1=[2, 1], 或是v2=[1, 3], 則它的位置就是v=a1*v1+a2*v2. 也就是說子空間是span(v1, v2), 但是v1和v2沒有正交, 可使用Gram-Schmidt法
		III. 非線性變換
			🤔. 不合線性變換定義則為非線性

        -------------------------------------------------------------
	c. 線性方程式
		I. 高斯消去法
		reference:
		https://en.wikipedia.org/wiki/Gaussian_elimination
			😄. 是一個演算法, 可將矩陣A化為單位矩陣, 進而求得Ax=b的增廣矩陣[A|b]的解
			😄. 做法如下:
				😄. 用第一列消去(乘上特定常數)第二列的第一項.
				😄. 用第一列以及被消去第一項後的第二列來消去第三列的第一項和第二項, 依此類推, 直到最後一列
				😄. 此時最後一列只會剩下最後有一項, 最後一項自然得到解
				😄. 將解帶入倒數第二項(此時剩下最後兩項), 可得倒數第二項的解, 再將最後一項的解以及倒數第二項的解帶入倒數第三列中, 以此類推, 直到所有解都出來, 最後矩陣A會化為單位矩陣I, 而b則是會化為"解". [A|b]=>[I|s]
		II. 可逆矩陣
			😄. 存在A^(-1)使得A*A^(-1)=I
			😄. 只有方陣才有逆矩陣
			😄. 行列式不等于0的方陣一定可逆! Ax=b有唯一解
			😄. 行列式等於0的方陣必定不可逆! Ax=b有無限多解或無解
			😄. 在之前討論的線性座標變換之下, 若是A做座標變換到B座標維度發生改變(例如R3->R2), 則矩陣不是方陣, 所以沒有逆矩陣, 也就是說A可以變換到B, 但B無法逆向變換回A, 這其實也蠻直觀的, 維度發生改變意味著有些資訊遺失了故無法逆向還原了, 這裡需要特別注意
			😄. 知道矩陣A的情況下求逆矩陣A^(-1)的方法
				😄. 伴隨矩陣法
				😄. 高斯-喬丹消去法(此法的應用較為廣泛, 也就為高效), 方法如下
					😄. 將[A|I]化為[I|A^(-1)], 這個過程只要把用高斯消去法將A化為I, 則原本[A|I]右邊的I自動就會化為A^(-1)
		III. 可對角化矩陣(可求解方程)
		reference:
		https://www.youtube.com/watch?v=pT5ci1DlvYY&ab_channel=CUSTCourses
			😄. 矩陣A必須是方陣(非方陣也無對角線)
			😄. n*n方陣A必須有n個線性獨立的特徵向量
			😄. A的n個特徵值都不同, 必定可對角化(因為必定有n個特徵向量)
			😄. 可對角化矩陣A=P*D*P^(-1)<=>P^(-1)*A*P=D, 其中P為特徵向量組成的矩陣, D為對角矩陣(自乘較易), 其對角線元素為特徵值. A^k=(P*D*P^(-1))^k=P*(D^k)*P^(-1)
			😄. 相似矩陣P^(-1)*A*P=B, A與B相似, A與B有相同的特徵值(特徵向量不一定相同), 且行列式相同

        -------------------------------------------------------------
	d. 奇異值(singular value)問題
		I. singular value問題與eigenvalue問題很像, 但他們實際上算的東西不一樣! 奇異值問題算的是矩陣A"轉置(共軛轉置)"後向量能否雙向轉換, 特徵向量沒有考慮矩陣A的轉置, 這是兩個問題關鍵差別. 由於在奇異值問題中矩陣A多了考慮了轉置的操作, 所以他能計算非方陣(方陣也可以)的問題. 兩個問題雖然計算的東西不同, 但是奇異值問題仍舊在某種程度上可以看做是特徵值問題的推廣
		II. 剛才在逆矩陣的研究中提到"A矩陣若為方陣才有逆矩陣A^(-1)". 此時輸入向量v通過矩陣A從原座標系統S轉換到另一個座標系統S'的向量v', 若想要從S'轉換向量u'到S, 需要逆矩陣A^(-1)來轉換. 由於A是"方陣"所以向量在不同坐標系轉換後, "資訊"並沒有丟失(可以雙向轉換). 但若A不是方陣, 則無逆矩陣, 也就是說v從S座標系統轉換到S'座標系統中的v', v'無法轉換回v, 轉換後的向量資訊丟失了(只能單向轉換)
		III. A若不是方陣雖然沒有逆矩陣A^(-1)存在, 但轉置矩陣A^(T)是必定存在的, 透過A^(T)我們可以建置"另類的雙向轉換"
		IV. 我們知道eigenvalue和eigenvector適用於方陣Av=λv. 但是A若不是n*n方陣, 而是n*m矩陣, 則奇異值和奇異向量滿足以下:
			🤔. Au=σv, 
			🤔. A^(T)v=σu
			🤔. 其中u為左奇異向量, v為右奇異向量
		V. 有了以上條件後, 會發現u透過A從S座標系統轉換到S'座標系統的σv. 而v透過反向透過A^(T)轉換回u, 但是!! 要注意座標系統並沒有從S'轉換回S, 因為A^(T)不是A^(-1), 所以A^(T)v=σu實際上沒有從S'轉換回S, 而是準換到A^(T)的對應座標系統去了. 
		VI. 在方陣問題中所有向量都可透過逆矩陣在S和S'間來回轉換, 但是奇異值問題中, 轉置矩陣沒有允許所有向量來回轉換(只允許奇異向量), 當然也就不存在S和S'之間的轉換(只有奇異向量可任意轉換).
		VII. 左奇異向量集合U為A^(T)*A的特徵向量集合, 右奇異向量集合V為A*A^(T)的特徵向量集合.
		VIII. 由於任意矩陣和其轉置矩陣的乘積M*M^(T)都為"對稱矩陣", 而對稱矩陣的特徵向量必為互相正交, 所以右向量集合U為座標系統S的一組正交基底, 左向量集合V為經過A轉換後在座標系統S'的一組正交基底. 這也是關鍵性的性質
		IX. 直觀理解
			😄. A矩陣本身便是拉伸, 旋轉, 反射. 而特徵向量就是A矩陣拉伸的方向, 特徵值就是拉伸大小, 這些在前面已經說過無數次了. 那奇異向量呢? 如何理解? 

        -------------------------------------------------------------
	e. 向量微積分
