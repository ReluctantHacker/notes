|###################################################################|
A. 統計學的三大本質
        -------------------------------------------------------------
	a. 採樣(隨機)
		I. 基本概念
			🤔. 母體(總體, population), 所有數據的集合, 例如一個城市所有人的身高數據集合
			🤔. 樣本(samples), 從母體中"隨機"抽樣出來的數據, 他們的平均值稱作"樣本均值"
			🤔. 期望值(expected value), 即是從母體中抽樣一數據, 該數據的合理"預測值", 這個值實際上就是母體的平均值, 是所有數據乘上本身數據發生的機率後加總(他不是樣本的平均值, 別搞混, 概念不同)
			🤔. 隨機的本質:
				😄. 隨機的本質就是"無法預測性(不確定性)", 某個時間的某個地點會發生甚麼"事件"無法預測, 這是所謂的隨機. 而隨機中之所以會有"規律", 是因為我們給了"隨機"一些限制, 例如某個時間地點會發生的"事件"只能有幾種事件, 例如擲骰子, 只會有1點, 2點...6點, 共6種事件, 這就是"限制事件範圍", 而這個限制讓"隨機"有了邊界, 進而有了"模式", 也就是有了所謂"分布", 而這個分布就是隨機的某種"規律". 但如果"隨機"本身沒有任何限制, 則某時某地發生的事件是完全沒有邊界的, 即是任意的事件都可能發生, 也就沒有"模式", 沒有"分布", 沒有"規律". 這是一種完全隨機. 完全無法預測的隨機. 
			🤔. 隨機變量(random variable)
				😄. 隨機變量是一個函數，它將樣本空間中的結果（這些結果通常是不確定的）映射為數字。例如，在投擲骰子的情況下，隨機變量 
𝑋可以將每次擲出來的點數轉換為數字1 到6。
			🤔. 事件(event)
				😄. 事件是樣本空間中的特定情況。例如，我們可以說「事件 A 是骰子的點數為偶數」，那麼這個事件可以用隨機變量來表達為「𝑋=2, 4, 或 6」。此時，事件 A 是由隨機變量 𝑋 取值為 2、4 或 6 時的集合。 隨機變量本身的每個取值可以被視為一個事件。例如，在骰子投擲中，「𝑋=3」就是一個事件，即「骰子點數為 3」這個具體結果。而某事件發生的機率可以寫成：𝑃(𝑋=1)=𝑃(𝑋=2)=⋯=𝑃(𝑋=6)=1/6
			🤔. 機率
			reference:
			https://medium.com/@makerincollege2018/%E5%8F%A4%E5%85%B8%E6%A9%9F%E7%8E%87%E8%AB%96-%E4%B8%8A%E5%B8%9D%E4%B8%8D%E6%93%B2%E9%AA%B0%E5%AD%90%E5%97%8E-%E7%B1%B3%E5%85%8B%E7%8E%8B%E7%9A%84%E7%B5%B1%E8%A8%88%E8%AC%9B%E5%A0%82-episode-1-a1d207eec8dc
			https://zh.wikipedia.org/zh-tw/%E6%A6%82%E7%8E%87%E8%AE%BA
				😄. 古典機率(Laplace提出, 是最早對於機率的定義)
					😄. 定義
						😄. 無差別原則(principle of indifference)
							😄. 每個事件發生的可能性相同(等可能), 這個定義被稱作"無差別原則(principle of indifference)", 古典機率完全是根據這個原則建立的
							😄. 舉例: A事件元素數目/事件空間中所有元素數目, 例如袋中10顆球裡有一顆紅球, 則紅球抽中機率為1/10. 又例如骰子有6點, 擲出1點的機率是1/6
						reference:
						http://philosophychina.cssn.cn/fzxk/ljx/201507/t20150713_2732083.shtml
						😄. 不可分割原則
							😄. 最關鍵的問題在於principle of indifference. 知名的"書矛盾"就明顯的呈現出問題所在, 圖書館有紅色書, 藍色書, 黃色書, 問紅色書的概率和非紅色書的概率有多少? 按照principle of indifference, 紅色書的概率為1/2, 而非紅色書的概率為1/2, 但這顯然不對, 若要使之沒有矛盾, 必須加入"不可分割"限制條件(即事件本身已經是基本事件了, 不能再分出A事件, B事件等等之類的), 但是不可分割原則肯定不適用於連續情況, 因為在連續情況下你永遠能分出更小的, 例如實數線段你無法分割出最小段. (其實"不可分割"的概念本身就是"離散"的.)
						😄. 無差別原則"等價"於不可分割原則
							😄. 兩個事件若發生的可能性不同, 則事件必定可以分割, 同樣的事件若是不能再分割了, 則其必定等機率! 舉例來說一個硬幣, 正面概率0.6, 反面概率0.4, 則可分割為{正-1, 正-2, 正-3, 正-4, 正-5, 正-6, 反-1, 反-2, 反-3, 反-4}
	
								reference:
														http://philosophychina.cssn.cn/fzxk/ljx/201507/t20150713_2732083.shtml
					😄. 應用
						😄. 此定義在現實生活中被廣泛運用於"事件發生的機率值是確定的", 理論根據是"如果沒有足夠的論據來證明一個事件機率大於另一個事件機率, 則兩事件可被認為機率值相同.
					😄. 古典機率定義的缺陷
						😄. 無法處理連續問題(非離散問題)
							😄. 例如從0到1選一個實數, 該實數大於0.5的機率是多少, 你必須把所有大於0.5的實數的機率加總, 但有一個問題是每一個實數的機率實際上都是0!!! 因為每一個實數都是0到1這個數線上面的"點", 點是沒有大小的(他是0維度), 這意味著你選中一個實數的可能性是0, 你根本不可能選中一個實數, 你只有可能選中一個"實數線段". 你也無法使用"積分", 因為在這裡使用積分, 實際上是把"無窮小"的"線段(一維度)"全部加起來得到完整的0.5到1的線段, 但在古典機率定義中, 所有事件都是"離散"的, 他們都是"點", 你把所有點都加起來, 他依舊不是線, 因為點本身是0維度, 你必須要把"無窮小線段"加起來, 才能得到線(這就是機率密度的概念, 後面公設化機率會提到), 所以你無法處理連續問題, 因為"連續"本身意味著他不是0維度, 而是至少1維度以上.
							😄. 如果將選到0~0.2的事件設定為A, 0.2~0.4設定為B, 0.4~0.6設定為C, 0.6~0.8設定為D, 0.8~1設定為E. 這樣的話就能巧妙避免"連續"的問題. 這叫做"有限分割", 此法可行, 但在概念上他是離散的, 如果我們要找某個實數點位置的"機率密度"(也就是機率在該點的變化情況), 那此法就不可行了. 當然在這個實數例子問題上由於0到1實數每個實數被選中的機率理論上是相等的, 因此沒有機率密度各點位置不一樣的情形, 但在其他許多問題上卻不是如此.
						😄. 兩事件發生的概率不同時, 古典機率無法適用, 例如硬幣正面發生概率為60%, 反面是40%. 古典機率無法適用.(其實可以利用類似加權的概念來處理這個問題, 但這實際上已經借用到公設化機率的概念了.)

				😄. 統計機率(頻率學派)
					😄. 深刻意義(以及其定義):
						😄. 統計機率假設有"母體"分布的存在, 藉由抽樣數據的增加, 可以無限逼近真實的母體機率分布. P(A) = lim fn(A), 其中fn是每次測量到的頻率值, 當n趨近無限, 極限值P(A)就是"統計機率". 這是大數法則的一個實際應用.
				😄. 貝葉思機率(貝葉斯學派, 貝氏統計)
					😄. 深刻意義(定義):
						😄. 不假設"母體"存在, 只關注當下的統計結果, 並將之稱為"機率". 先數入一個"先驗機率(即是新數據未取得前的統計機率, 或也可以透過一些合理的假設定義出來)", 先驗機率結合當下新數據的結果, 產出一個新的機率, 這個機率就是當下"真實"的機率, 這個機率在下次遇到新數據時, 會變成需要輸入的先驗數據. 更以更值觀的說, 統計機率把"機率"定義成事件發生的"確切可能性", 但是貝葉斯機率把機率定義成事件發生的"信任程度(現有的統計結論)"
				😄. 公設化機率(現代機率定義, 也是最完善)
					😄. 深刻意義:
						😄. 數學與物理學有一件事情不太一樣, 就是數學的根本法則(不證而為真), 可以自己建立, 這些被認為建立的法則(適合的)被稱為"公設", 歐幾里得幾何原本的幾何公設就是最典型最有名的例子. 同樣機率的定義和概念也可以用同樣的方式去更加合理的建立.
					😄. Kolmogorov’s Axioms
						😄. 隨機實驗的樣本空間 S 中，如果有一個集合函數 P(·) ，滿足下列公設者，稱為機率集合函數，簡稱機率函數。
							😄. 公設1(非負性)： P(A) ≥ 0 ，對任意事件 A ⊂ S

							😄. 公設2(歸一化)： P(S) = 1

							😄. 公設3(可加性)： 假設 A、B、C …為樣本空間S中的一組事件，且他們之間倆倆互斥(disjoint, 就是集合概念的互斥)，則事件連集的機率必等於分別事件的機率加總。
					🤔. 樣本空間(sample space)
						😄. "樣本空間"和"母體(population)"的概念有點類似, 但並不一樣. 母體是所有東西的集合, 它包含了"分布"的概念, 例如母體中有香蕉3根, 蘋果2顆, 茄子1條, 則母體是{香蕉, 香蕉, 香蕉, 蘋果, 蘋果, 茄子}. 母體包含了"分布"的概. 但樣本空間則不包含分布的概念, 只有分類的集合. 例如剛才的例子中樣本空間會是{香蕉, 蘋果, 茄子}, 沒有分布的概念在裏頭. 以下是一些比較和參考:
							https://math.stackexchange.com/questions/1660038/populations-and-sample-spaces
							https://stats.stackexchange.com/questions/175027/what-is-the-difference-between-sample-space-and-population#:~:text=The%20population%20is%20the%20set%20of%20all%20units,your%20random%20process%20picks%20a%20person%2C%20John%20Smith.
					🤔. 處理連續機率
						😄. 由於


	b. 分布(隨機中的規律)
		I. 大數法則(Law of large numbers)
			🤔. 隨著採集樣本數量的增加, 這些樣本的平均值會趨向於總體(即母體, 樣本的採集處)的平均值(即期望值). 例如一個城市人民的平均身高, 我們抽取1000為市民測量身高, 這1000位市民的平均身高用來估計總體(母體, 整體)市民的平均身高, 當抽樣的市民數量越多, 樣本均值會約接近真實的母體均值(期望值).
				😄. 弱大數法則
					😄. 大數法則成立的先決條件是"採樣"本身是隨機的! 你如果故意抽取身高較高的市民, 拿結果肯定偏離市民母體身高平均值. 弱大數法則可用切比學夫(chebyshev)不等式證明, 而chebyshev不等式可用馬爾可夫(Markov)不等式證明, 馬爾可夫不等式的證明可參考wikipedia, 有一個非常精妙簡潔的證明, 只用到了簡單的積分:
					reference:
					https://zh.wikipedia.org/zh/%E9%A6%AC%E7%88%BE%E5%8F%AF%E5%A4%AB%E4%B8%8D%E7%AD%89%E5%BC%8F
		II. 中央極限定理(Central Limit Theorem)
	c. 機率(藉由規律預測未知數據)

|###################################################################|
B. 採樣數學

|###################################################################|
C. 分布數學

|###################################################################|
D. 機率數學


E. 基本排列組合:
reference:
https://www.naer.edu.tw/upload/1/16/doc/864/%E6%99%AE%E9%AB%98%E6%8E%92%E5%88%97%E7%94%9F.pdf
